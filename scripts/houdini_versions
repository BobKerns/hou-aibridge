#!/usr/bin/env uv run --script
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "click",
#     "requests",
#     "semver",
# ///

import os
import json
from pathlib import Path
from typing import Final
import click
import requests
import sys
import time
from datetime import datetime
from collections import defaultdict

HOUDINI_FALLBACK_VERSION: Final[str] = os.getenv("HOUDINI_FALLBACK_VERSION", "20.5.584")
HOUDINI_DEFAULT_MIN_VERSION: Final[str] = "20.5"
HOUDINI_VERSIONS_CACHE_NAME: Final[str] = "houdini_versions_cache.json"
HOUDINI_DEFAULT_CACHE_DIR: Final[Path] = Path(os.getenv("CACHE_DIRECTORY", Path.home() / '.aibridge-cache'))
HOUDINI_VERSIONS_CACHE: Final[Path] = HOUDINI_DEFAULT_CACHE_DIR / HOUDINI_VERSIONS_CACHE_NAME

def parse_houdini_version(version_str: str, build_str: str|None=None):
    """Parse Houdini version string with optional build number for comparison."""
    try:
        parts = version_str.split('.')

        # Handle Houdini's two-part version format (e.g., "20.5")
        if len(parts) == 2:
            major, minor = map(float, parts)  # Use float to handle "20.5"
            patch = int(build_str) if build_str else 0
            # Convert to tuple for comparison
            return (int(major), int(minor * 10), patch)
        else:
            while len(parts) < 3:
                parts.append('0')
            major, minor, patch = map(int, parts[:3])
            return (major, minor, patch)
    except Exception as e:
        print(f"Failed to parse version: {version_str}.{build_str} - {e}", file=sys.stderr)
        return (0, 0, 0)

def compare_versions(version1, version2):
    """Compare two Houdini version strings (with build numbers)."""
    v1_parts = version1.split('.')
    v2_parts = version2.split('.')

    # Extract main version and build
    if len(v1_parts) == 3:
        v1_main, v1_build = '.'.join(v1_parts[:2]), v1_parts[2]
    else:
        v1_main, v1_build = version1, "0"

    if len(v2_parts) == 3:
        v2_main, v2_build = '.'.join(v2_parts[:2]), v2_parts[2]
    else:
        v2_main, v2_build = version2, "0"

    # Compare main versions first
    v1_tuple = parse_houdini_version(v1_main)
    v2_tuple = parse_houdini_version(v2_main)

    if v1_tuple != v2_tuple:
        return -1 if v1_tuple < v2_tuple else 1

    # If main versions are equal, compare build numbers
    return -1 if int(v1_build) < int(v2_build) else (0 if int(v1_build) == int(v2_build) else 1)

def is_version_gte(version, min_version):
    """Check if version is greater than or equal to min_version."""
    return compare_versions(version, min_version) >= 0

def get_version_range_for_testing(min_version: str="20.5", cache_file: Path=HOUDINI_VERSIONS_CACHE):
    """Get oldest and newest builds for each major.minor release using authenticated API."""
    # Check for environment variable override first
    env_versions = os.environ.get("HOUDINI_TEST_VERSIONS")
    if env_versions:
        versions = env_versions.split(",")
        # Filter versions based on minimum
        return [v for v in versions if is_version_gte(v, min_version)]

    # Check if we should use cache first (for GitHub Actions)
    if os.environ.get("CACHE_HIT", "true") == "true" and cache_file.exists():
        # Check cache age
        cache_age_hours = 0
        try:
            mtime = os.path.getmtime(cache_file)
            cache_age_hours = (time.time() - mtime) / 3600
        except Exception as e:
            print(f"Failed to get cache file modification time: {e}", file=sys.stderr)
            pass

        # Use cache if it's less than 24 hours old
        if cache_age_hours < 24:
            try:
                with open(cache_file, 'r') as f:
                    cached_data = json.load(f)
                    cached_versions = cached_data.get("versions", [])
                    # Filter cached versions by minimum
                    filtered = [v for v in cached_versions if v.split('.')[0] + '.' + v.split('.')[1] >= min_version]
                    if filtered:
                        print(f"Using cached versions (cache is {cache_age_hours:.1f} hours old)", file=sys.stderr)
                        return filtered
            except Exception as e:
                print(f"Failed to read cache file: {e}", file=sys.stderr)
                pass

    # Default fallbacks in case API access fails - for Houdini 20.5+
    fallback_versions = [HOUDINI_FALLBACK_VERSION]  # Known production build for 20.5

    # Get credentials from environment
    username = os.environ.get("SIDEFX_USERNAME")
    password = os.environ.get("SIDEFX_PASSWORD")

    # If credentials aren't available, use fallbacks
    if not username or not password:
        print("SideFX credentials not found, using fallback versions", file=sys.stderr)
        return fallback_versions

    try:
        # Common browser-like headers
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Referer": "https://www.sidefx.com/login/",
            "Connection": "keep-alive"
        }

        # Create session and authenticate
        session = requests.Session()
        session.headers.update(headers)

        # First get the login page to obtain any CSRF tokens
        login_page = session.get("https://www.sidefx.com/login/")

        # Add a small delay to mimic human behavior
        time.sleep(1)

        # Prepare login data
        login_data = {
            "username": username,
            "password": password,
            "next": "/download/daily-builds/get/"  # Direct to builds page after login
        }

        # Extract CSRF token if present
        import re
        csrf_match = re.search(r'name="csrfmiddlewaretoken" value="([^"]+)"', login_page.text)
        if csrf_match:
            login_data["csrfmiddlewaretoken"] = csrf_match.group(1)
            session.headers.update({"Referer": "https://www.sidefx.com/login/"})

        # Perform login
        login_resp = session.post(
            "https://www.sidefx.com/login/",
            data=login_data,
            allow_redirects=True
        )
        if login_resp.status_code != 200:
            print(f"Login failed: {login_resp.status_code}", file=sys.stderr)
            return fallback_versions

        # Add another small delay
        time.sleep(1)

        # Get the build list
        build_resp = session.get("https://www.sidefx.com/download/daily-builds/get/")

        if build_resp.status_code != 200:
            print(f"Failed to get build list: {build_resp.status_code}", file=sys.stderr)
            return fallback_versions

        # Try to parse the JSON response
        try:
            build_data = build_resp.json()
        except json.JSONDecodeError as e:
            print(f"Failed to parse JSON response: {e}", file=sys.stderr)
            return fallback_versions

        # Process the daily builds from the JSON structure
        production_builds = []

        # Check in daily_builds_releases
        for build in build_data.get("daily_builds_releases", []):
            # Only consider production builds (we know these are all "devel" for now)
            # Only consider standard Houdini (not Qt6, py310, etc.)
            if (build.get("product") == "houdini" and
                # Include both gold and devel releases
                (build.get("release") in ["gold", "devel"]) and
                # Make sure the package exists
                build.get("package_exists") and
                # Not marked as bad quality
                not build.get("bad_quality")):

                version = build.get("version")
                build_num = build.get("build")

                # Check if version meets minimum requirement
                if version and build_num:
                    full_version = f"{version}.{build_num}"

                    # Only include versions >= min_version
                    if is_version_gte(version, min_version):
                        production_builds.append({
                            "full_version": full_version,
                            "version": version,
                            "build": build_num,
                            "release": build.get("release")
                        })

        # Group by major.minor version
        version_groups = defaultdict(list)
        for build in production_builds:
            version_groups[build["version"]].append(build)

        # For each major.minor, select oldest and newest
        test_versions = []
        for version, builds in version_groups.items():
            # Sort by build number
            sorted_builds = sorted(builds, key=lambda b: int(b["build"]))

            if sorted_builds:
                # Get oldest production build for this version
                oldest = sorted_builds[0]["full_version"]
                test_versions.append(oldest)

                # Get newest production build for this version if different
                if len(sorted_builds) > 1:
                    newest = sorted_builds[-1]["full_version"]
                    if newest != oldest:
                        test_versions.append(newest)

                # If there's a gold release, ensure it's included
                gold_builds = [b["full_version"] for b in sorted_builds if b["release"] == "gold"]
                if gold_builds and gold_builds[0] not in test_versions:
                    test_versions.append(gold_builds[0])

        # Fallback if we couldn't find any versions
        if not test_versions:
            return fallback_versions

        # Cache the results
        if cache_file:
            try:
                with open(cache_file, 'w') as f:
                    # Include metadata about when cache was created
                    cache_data = {
                        "versions": test_versions,
                        "cache_date": datetime.now().isoformat(),
                        "min_version": min_version
                    }
                    json.dump(cache_data, f)
            except Exception as e:
                print(f"Failed to write cache: {e}", file=sys.stderr)

        return test_versions

    except Exception as e:
        print(f"Error fetching versions: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        return fallback_versions


@click.command()
@click.option('--cache-dir',
              default=os.getenv("HOUDINI_VERSIONS_CACHE",
                                HOUDINI_DEFAULT_CACHE_DIR),
              help='Directory to cache Houdini versions.')
@click.option('--min-version',
              default=os.getenv("HOUDINI_MIN_VERSION",
                                HOUDINI_DEFAULT_MIN_VERSION),
              help='Minimum Houdini version to consider.')
def main(cache_dir: Path|str=HOUDINI_VERSIONS_CACHE,
         min_version: str="20.5"):
    """Get Houdini versions for testing."""

    cache_dir = Path(cache_dir)
    cache_dir.mkdir(exist_ok=True)
    cache_file = cache_dir / Path(HOUDINI_VERSIONS_CACHE_NAME).name
    # Get versions
    versions = get_version_range_for_testing(min_version, cache_file)

    # Output as JSON
    print(json.dumps(versions))

if __name__ == "__main__":
    main()
